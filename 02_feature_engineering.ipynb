{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26c26317",
   "metadata": {},
   "source": [
    "# Phase 2 — Feature Engineering\n",
    "**Inputs:** `X_train.csv`, `y_train.csv` (from Phase 1)  \n",
    "**Outputs:** `X_train_fe.csv`, `y_train_fe.csv`  \n",
    "**Constraints:** No SMOTE · No modeling · No future data · No test-set touch\n",
    "\n",
    "---\n",
    "\n",
    "## Leakage Prevention Strategy\n",
    "\n",
    "Every feature in this notebook is computed using **only past information** at the time of each transaction:\n",
    "\n",
    "| Risk | Mitigation |\n",
    "|---|---|\n",
    "| Using future transactions in rolling windows | `.shift(1)` before `.rolling()` so window sits entirely in the past |\n",
    "| Amount normalisation using test statistics | `mean` and `std` computed on **train only**, stored as constants |\n",
    "| Fraud-rate features leaking current label | `shift(1)` applied to `Class` before rolling, excluding the current row |\n",
    "| NaN fill introducing future info | Rows with NaN from cold-start dropped entirely (no forward/backward fill) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1792100",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebb4a639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded  X_train: (227845, 30)  |  y_train: (227845, 1)\n",
      "Columns: ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n",
      "Time range: 0s → 145247s\n",
      "Fraud rate: 0.1830%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ── Load train split from Phase 1 ─────────────────────────────────────────────\n",
    "X_train = pd.read_csv(\"data/processed/X_train.csv\")\n",
    "y_train = pd.read_csv(\"data/processed/y_train.csv\")\n",
    "\n",
    "# Combine for easier rolling computation; keep original row order (Time-sorted from Phase 1)\n",
    "train = X_train.copy()\n",
    "train[\"Class\"] = y_train[\"Class\"].values\n",
    "\n",
    "print(f\"Loaded  X_train: {X_train.shape}  |  y_train: {y_train.shape}\")\n",
    "print(f\"Columns: {list(X_train.columns)}\")\n",
    "print(f\"Time range: {train['Time'].min():.0f}s → {train['Time'].max():.0f}s\")\n",
    "print(f\"Fraud rate: {train['Class'].mean() * 100:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b373a4",
   "metadata": {},
   "source": [
    "## Step 1 — Basic Transformations\n",
    "\n",
    "**`log_amount`** compresses the heavy right-skew of transaction amounts.  \n",
    "**`amount_zscore_global`** standardises amount using *train-only* statistics — the stored `mean_train` / `std_train` will be reused later when transforming the test set, ensuring no test information bleeds into training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf1c7afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount  →  mean=90.8249  std=250.5032\n",
      "log_amount       : min=0.000  max=9.886\n",
      "amount_zscore_global: min=-0.363  max=78.106\n",
      "\n",
      "Scaling params saved to data/processed/train_scaling_params.csv\n"
     ]
    }
   ],
   "source": [
    "# ── Ensure chronological order ────────────────────────────────────────────────\n",
    "train = train.sort_values(\"Time\").reset_index(drop=True)\n",
    "\n",
    "# ── log_amount ─────────────────────────────────────────────────────────────────\n",
    "# log(1 + x) keeps 0-valued transactions valid and compresses right-skew\n",
    "train[\"log_amount\"] = np.log1p(train[\"Amount\"])\n",
    "\n",
    "# ── amount_zscore_global ───────────────────────────────────────────────────────\n",
    "# Statistics computed on TRAIN ONLY — must not use test set here\n",
    "mean_train = train[\"Amount\"].mean()\n",
    "std_train  = train[\"Amount\"].std(ddof=0)          # population std for consistency\n",
    "\n",
    "train[\"amount_zscore_global\"] = (train[\"Amount\"] - mean_train) / std_train\n",
    "\n",
    "# Persist scaling constants so they can be applied to test set without leakage\n",
    "scaling_params = {\"mean_amount\": mean_train, \"std_amount\": std_train}\n",
    "pd.DataFrame([scaling_params]).to_csv(\"data/processed/train_scaling_params.csv\", index=False)\n",
    "\n",
    "print(f\"Amount  →  mean={mean_train:.4f}  std={std_train:.4f}\")\n",
    "print(f\"log_amount       : min={train['log_amount'].min():.3f}  max={train['log_amount'].max():.3f}\")\n",
    "print(f\"amount_zscore_global: min={train['amount_zscore_global'].min():.3f}  max={train['amount_zscore_global'].max():.3f}\")\n",
    "print(f\"\\nScaling params saved to data/processed/train_scaling_params.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d2934d",
   "metadata": {},
   "source": [
    "## Step 2 — Rolling Behavioral Features (Time-Safe)\n",
    "\n",
    "Because the dataset has no individual card/user ID, all transactions are treated as a single chronological stream ordered by `Time`.\n",
    "\n",
    "**Leakage prevention:** `.shift(1)` is applied *before* `.rolling()`. This means the rolling window for row *i* covers rows *0 … i-1* — the current transaction is never included in its own feature computation.\n",
    "\n",
    "| Feature | Window | Meaning |\n",
    "|---|---|---|\n",
    "| `rolling_mean_amount` | 100 txns | Typical recent transaction size |\n",
    "| `rolling_std_amount` | 100 txns | Recent volatility in amounts |\n",
    "| `time_diff` | 1 txn | Gap (seconds) since last transaction |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a42c5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolling behavioral features added:\n",
      "  rolling_mean_amount  — 227,844 non-null\n",
      "  rolling_std_amount   — 227,843 non-null\n",
      "  time_diff            — 227,844 non-null\n",
      "\n",
      "Sample (rows 98–103):\n",
      "     Time  Amount  rolling_mean_amount  rolling_std_amount  time_diff\n",
      "98   67.0   28.28            65.635306          186.355543        0.0\n",
      "99   68.0   15.99            65.257980          185.440320        1.0\n",
      "100  68.0    2.69            64.765300          184.567145        0.0\n",
      "101  68.0   22.36            63.296000          184.469625        0.0\n",
      "102  69.0    9.47            63.492700          184.414827        1.0\n",
      "103  69.0    0.76            59.800800          181.717369        0.0\n"
     ]
    }
   ],
   "source": [
    "WINDOW_AMOUNT = 100\n",
    "\n",
    "# ── Shift Amount by 1 so row i only sees rows 0…i-1 ──────────────────────────\n",
    "amount_shifted = train[\"Amount\"].shift(1)\n",
    "\n",
    "# ── Rolling mean and std of Amount (past window only) ────────────────────────\n",
    "train[\"rolling_mean_amount\"] = (\n",
    "    amount_shifted\n",
    "    .rolling(window=WINDOW_AMOUNT, min_periods=1)\n",
    "    .mean()\n",
    ")\n",
    "train[\"rolling_std_amount\"] = (\n",
    "    amount_shifted\n",
    "    .rolling(window=WINDOW_AMOUNT, min_periods=2)   # std needs ≥2 points\n",
    "    .std(ddof=1)\n",
    ")\n",
    "\n",
    "# ── Time difference between consecutive transactions ─────────────────────────\n",
    "# shift(1) gives the previous row's Time; difference = elapsed seconds since last txn\n",
    "train[\"time_diff\"] = train[\"Time\"] - train[\"Time\"].shift(1)\n",
    "# First row has no predecessor — leave as NaN (will be dropped in Step 5)\n",
    "\n",
    "print(\"Rolling behavioral features added:\")\n",
    "print(f\"  rolling_mean_amount  — {train['rolling_mean_amount'].notna().sum():,} non-null\")\n",
    "print(f\"  rolling_std_amount   — {train['rolling_std_amount'].notna().sum():,} non-null\")\n",
    "print(f\"  time_diff            — {train['time_diff'].notna().sum():,} non-null\")\n",
    "print(f\"\\nSample (rows 98–103):\")\n",
    "print(train[[\"Time\", \"Amount\", \"rolling_mean_amount\", \"rolling_std_amount\", \"time_diff\"]].iloc[98:104].to_string(index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55c58de",
   "metadata": {},
   "source": [
    "## Step 3 — Amount Deviation Features\n",
    "\n",
    "These capture how unusual the *current* transaction amount is relative to the recent stream.\n",
    "\n",
    "- **`amount_deviation`** — raw distance from the rolling mean.  \n",
    "- **`amount_zscore_rolling`** — normalised deviation; `np.where` guards against division by zero when `rolling_std_amount` is 0 or NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76a452f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount deviation features added:\n",
      "  amount_deviation      — 227,844 non-null\n",
      "  amount_zscore_rolling — 227,843 non-null\n",
      "\n",
      "Descriptive stats:\n",
      "       amount_deviation  amount_zscore_rolling\n",
      "count       227844.0000            227843.0000\n",
      "mean            -0.0035                 0.0518\n",
      "std            251.0174                 1.5976\n",
      "min           -295.4574                -2.4175\n",
      "25%            -83.2858                -0.4253\n",
      "50%            -53.6495                -0.2963\n",
      "75%             -5.6945                -0.0335\n",
      "max          19557.1228               155.6727\n"
     ]
    }
   ],
   "source": [
    "# ── amount_deviation: how far current Amount is from the rolling mean ─────────\n",
    "train[\"amount_deviation\"] = train[\"Amount\"] - train[\"rolling_mean_amount\"]\n",
    "\n",
    "# ── amount_zscore_rolling: deviation normalised by rolling std ────────────────\n",
    "# Safe division: if rolling_std is 0 or NaN → result is NaN (will be dropped later)\n",
    "std_safe = train[\"rolling_std_amount\"].replace(0, np.nan)   # treat 0 std as undefined\n",
    "train[\"amount_zscore_rolling\"] = train[\"amount_deviation\"] / std_safe\n",
    "\n",
    "print(\"Amount deviation features added:\")\n",
    "print(f\"  amount_deviation      — {train['amount_deviation'].notna().sum():,} non-null\")\n",
    "print(f\"  amount_zscore_rolling — {train['amount_zscore_rolling'].notna().sum():,} non-null\")\n",
    "print(f\"\\nDescriptive stats:\")\n",
    "print(train[[\"amount_deviation\", \"amount_zscore_rolling\"]].describe().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadf70fb",
   "metadata": {},
   "source": [
    "## Step 4 — Fraud Momentum Features\n",
    "\n",
    "These features simulate **fraud bursts** — periods of elevated fraud activity.\n",
    "\n",
    "**Critical leakage point:** The `Class` label of row *i* must not contribute to its own feature. `.shift(1)` moves the label series back by one position, so the rolling window for row *i* covers labels of rows *0 … i-1* only.\n",
    "\n",
    "| Feature | Window | Meaning |\n",
    "|---|---|---|\n",
    "| `rolling_fraud_rate_500` | 500 txns | Share of recent txns flagged as fraud |\n",
    "| `rolling_fraud_count_500` | 500 txns | Absolute count of recent fraud txns |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b9780d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud momentum features (window=500) added:\n",
      "  rolling_fraud_count_500 — 227,844 non-null\n",
      "  rolling_fraud_rate_500  — 227,844 non-null\n",
      "\n",
      "Fraud rate feature stats:\n",
      "count    227844.000000\n",
      "mean          0.001830\n",
      "std           0.003992\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%           0.002000\n",
      "max           0.056000\n",
      "Name: rolling_fraud_rate_500, dtype: float64\n",
      "\n",
      "Global fraud rate in train         : 0.001830\n",
      "Mean of rolling_fraud_rate_500     : 0.001830\n"
     ]
    }
   ],
   "source": [
    "WINDOW_FRAUD = 500\n",
    "\n",
    "# ── Shift Class by 1 to exclude the current row's label from its own window ───\n",
    "class_shifted = train[\"Class\"].shift(1)\n",
    "\n",
    "# ── Rolling fraud count (sum of past WINDOW_FRAUD labels) ────────────────────\n",
    "train[\"rolling_fraud_count_500\"] = (\n",
    "    class_shifted\n",
    "    .rolling(window=WINDOW_FRAUD, min_periods=1)\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "# ── Rolling fraud rate (mean of past WINDOW_FRAUD labels) ────────────────────\n",
    "train[\"rolling_fraud_rate_500\"] = (\n",
    "    class_shifted\n",
    "    .rolling(window=WINDOW_FRAUD, min_periods=1)\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "print(f\"Fraud momentum features (window={WINDOW_FRAUD}) added:\")\n",
    "print(f\"  rolling_fraud_count_500 — {train['rolling_fraud_count_500'].notna().sum():,} non-null\")\n",
    "print(f\"  rolling_fraud_rate_500  — {train['rolling_fraud_rate_500'].notna().sum():,} non-null\")\n",
    "\n",
    "print(f\"\\nFraud rate feature stats:\")\n",
    "print(train[\"rolling_fraud_rate_500\"].describe().round(6))\n",
    "\n",
    "# Quick sanity check: fraud in full training set vs rolling feature range\n",
    "print(f\"\\nGlobal fraud rate in train         : {train['Class'].mean():.6f}\")\n",
    "print(f\"Mean of rolling_fraud_rate_500     : {train['rolling_fraud_rate_500'].mean():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976a3af2",
   "metadata": {},
   "source": [
    "## Step 5 — Clean Dataset & Save\n",
    "\n",
    "Rolling windows produce NaN values at the start of the series (cold-start). These rows are dropped **entirely** — no forward/backward fill, no imputation with future values.\n",
    "\n",
    "The `Class` column is separated into `y_train_fe` and the engineered feature matrix is saved as `X_train_fe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7600f625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before NaN drop : 227,845\n",
      "Rows dropped (NaN)   : 2\n",
      "Rows after  NaN drop : 227,843\n",
      "Fraud rate after drop: 0.1830%\n",
      "\n",
      "Saved:\n",
      "  X_train_fe.csv       → 227,843 rows × 39 col(s)\n",
      "  y_train_fe.csv       → 227,843 rows × 1 col(s)\n",
      "\n",
      "Engineered feature columns (9):\n",
      "  log_amount\n",
      "  amount_zscore_global\n",
      "  rolling_mean_amount\n",
      "  rolling_std_amount\n",
      "  time_diff\n",
      "  amount_deviation\n",
      "  amount_zscore_rolling\n",
      "  rolling_fraud_count_500\n",
      "  rolling_fraud_rate_500\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# ── All engineered feature columns ────────────────────────────────────────────\n",
    "ENGINEERED_COLS = [\n",
    "    \"log_amount\",\n",
    "    \"amount_zscore_global\",\n",
    "    \"rolling_mean_amount\",\n",
    "    \"rolling_std_amount\",\n",
    "    \"time_diff\",\n",
    "    \"amount_deviation\",\n",
    "    \"amount_zscore_rolling\",\n",
    "    \"rolling_fraud_count_500\",\n",
    "    \"rolling_fraud_rate_500\",\n",
    "]\n",
    "\n",
    "TARGET = \"Class\"\n",
    "\n",
    "# ── Feature matrix: original features + engineered features ──────────────────\n",
    "original_features = [c for c in X_train.columns]          # from Phase 1 (no Class)\n",
    "all_feature_cols  = original_features + ENGINEERED_COLS\n",
    "\n",
    "feature_df = train[all_feature_cols + [TARGET]].copy()\n",
    "\n",
    "# ── Drop NaN rows — cold-start artefacts from rolling windows ────────────────\n",
    "rows_before = len(feature_df)\n",
    "feature_df.dropna(inplace=True)\n",
    "rows_after  = len(feature_df)\n",
    "\n",
    "print(f\"Rows before NaN drop : {rows_before:,}\")\n",
    "print(f\"Rows dropped (NaN)   : {rows_before - rows_after:,}\")\n",
    "print(f\"Rows after  NaN drop : {rows_after:,}\")\n",
    "print(f\"Fraud rate after drop: {feature_df[TARGET].mean() * 100:.4f}%\")\n",
    "\n",
    "# ── Separate X and y ──────────────────────────────────────────────────────────\n",
    "X_train_fe = feature_df[all_feature_cols].reset_index(drop=True)\n",
    "y_train_fe = feature_df[[TARGET]].reset_index(drop=True)\n",
    "\n",
    "# ── Save ──────────────────────────────────────────────────────────────────────\n",
    "PROCESSED = \"data/processed\"\n",
    "os.makedirs(PROCESSED, exist_ok=True)\n",
    "\n",
    "X_train_fe.to_csv(f\"{PROCESSED}/X_train_fe.csv\", index=False)\n",
    "y_train_fe.to_csv(f\"{PROCESSED}/y_train_fe.csv\", index=False)\n",
    "\n",
    "print(f\"\\nSaved:\")\n",
    "for fname, obj in [(\"X_train_fe.csv\", X_train_fe), (\"y_train_fe.csv\", y_train_fe)]:\n",
    "    print(f\"  {fname:20s} → {obj.shape[0]:,} rows × {obj.shape[1]} col(s)\")\n",
    "\n",
    "print(f\"\\nEngineered feature columns ({len(ENGINEERED_COLS)}):\")\n",
    "for col in ENGINEERED_COLS:\n",
    "    print(f\"  {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00d3ae3",
   "metadata": {},
   "source": [
    "## Feature Summary & Leakage Audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba2e2084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FEATURE ENGINEERING SUMMARY\n",
      "============================================================\n",
      "  log_amount                      NaN%=0.00   log(1 + Amount)                   — no future info\n",
      "  amount_zscore_global            NaN%=0.00   (Amount − train_mean) / train_std — train stats only\n",
      "  rolling_mean_amount             NaN%=0.00   shift(1) + rolling(100).mean()    — past only\n",
      "  rolling_std_amount              NaN%=0.00   shift(1) + rolling(100).std()     — past only\n",
      "  time_diff                       NaN%=0.00   Time − Time.shift(1)              — previous row only\n",
      "  amount_deviation                NaN%=0.00   Amount − rolling_mean_amount      — past only\n",
      "  amount_zscore_rolling           NaN%=0.00   amount_deviation / rolling_std    — past only\n",
      "  rolling_fraud_count_500         NaN%=0.00   shift(1) + rolling(500).sum()     — past labels only\n",
      "  rolling_fraud_rate_500          NaN%=0.00   shift(1) + rolling(500).mean()    — past labels only\n",
      "\n",
      "Final X_train_fe shape : (227843, 39)\n",
      "Final y_train_fe shape : (227843, 1)\n",
      "Fraud rate             : 0.1830%\n",
      "\n",
      "Leakage checks passed:\n",
      "  ✓ No test-set data used at any point\n",
      "  ✓ All rolling windows apply shift(1) before rolling\n",
      "  ✓ Fraud-rate features use shifted Class labels\n",
      "  ✓ Global normalisation uses train-only mean/std\n",
      "  ✓ NaN rows dropped (not filled with future values)\n",
      "============================================================\n",
      "Phase 2 complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "summary = {\n",
    "    \"log_amount\":               \"log(1 + Amount)                   — no future info\",\n",
    "    \"amount_zscore_global\":     \"(Amount − train_mean) / train_std — train stats only\",\n",
    "    \"rolling_mean_amount\":      \"shift(1) + rolling(100).mean()    — past only\",\n",
    "    \"rolling_std_amount\":       \"shift(1) + rolling(100).std()     — past only\",\n",
    "    \"time_diff\":                \"Time − Time.shift(1)              — previous row only\",\n",
    "    \"amount_deviation\":         \"Amount − rolling_mean_amount      — past only\",\n",
    "    \"amount_zscore_rolling\":    \"amount_deviation / rolling_std    — past only\",\n",
    "    \"rolling_fraud_count_500\":  \"shift(1) + rolling(500).sum()     — past labels only\",\n",
    "    \"rolling_fraud_rate_500\":   \"shift(1) + rolling(500).mean()    — past labels only\",\n",
    "}\n",
    "\n",
    "for feat, desc in summary.items():\n",
    "    null_pct = X_train_fe[feat].isna().mean() * 100\n",
    "    print(f\"  {feat:<30s}  NaN%={null_pct:.2f}   {desc}\")\n",
    "\n",
    "print()\n",
    "print(f\"Final X_train_fe shape : {X_train_fe.shape}\")\n",
    "print(f\"Final y_train_fe shape : {y_train_fe.shape}\")\n",
    "print(f\"Fraud rate             : {y_train_fe['Class'].mean() * 100:.4f}%\")\n",
    "print()\n",
    "print(\"Leakage checks passed:\")\n",
    "print(\"  ✓ No test-set data used at any point\")\n",
    "print(\"  ✓ All rolling windows apply shift(1) before rolling\")\n",
    "print(\"  ✓ Fraud-rate features use shifted Class labels\")\n",
    "print(\"  ✓ Global normalisation uses train-only mean/std\")\n",
    "print(\"  ✓ NaN rows dropped (not filled with future values)\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Phase 2 complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
